{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as npplò7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1804874, 45)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  target                                       comment_text  \\\n",
       "0  59848     0.0  This is so cool. It's like, 'would you want yo...   \n",
       "\n",
       "   severe_toxicity  obscene  identity_attack  insult  threat  asian  atheist  \\\n",
       "0              0.0      0.0              0.0     0.0     0.0    NaN      NaN   \n",
       "\n",
       "   ...  article_id    rating  funny  wow  sad  likes  disagree  \\\n",
       "0  ...        2006  rejected      0    0    0      0         0   \n",
       "\n",
       "   sexual_explicit  identity_annotator_count  toxicity_annotator_count  \n",
       "0              0.0                         0                         4  \n",
       "\n",
       "[1 rows x 45 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97320, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000000</td>\n",
       "      <td>Jeff Sessions is another one of Trump's Orwell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7000001</td>\n",
       "      <td>I actually inspected the infrastructure on Gra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                       comment_text\n",
       "0  7000000  Jeff Sessions is another one of Trump's Orwell...\n",
       "1  7000001  I actually inspected the infrastructure on Gra..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "print(df_test.shape)\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97320, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9203</th>\n",
       "      <td>7009203</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56035</th>\n",
       "      <td>7056035</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  prediction\n",
       "9203   7009203         0.0\n",
       "56035  7056035         0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv('sample_submission.csv')\n",
    "print(sample.shape)\n",
    "sample.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting all the columns with null values\n",
    "columns_to_drop = df.columns[df.isnull().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id        0\n",
      "target    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns_to_drop,axis=1)\n",
    "print(df.isnull().sum()[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>created_date</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-09-29 10:50:41.987077+00</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thank you!! This would make my life a lot less...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-09-29 10:50:42.870083+00</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  target                                       comment_text  \\\n",
       "0  59848     0.0  This is so cool. It's like, 'would you want yo...   \n",
       "1  59849     0.0  Thank you!! This would make my life a lot less...   \n",
       "\n",
       "   severe_toxicity  obscene  identity_attack  insult  threat  \\\n",
       "0              0.0      0.0              0.0     0.0     0.0   \n",
       "1              0.0      0.0              0.0     0.0     0.0   \n",
       "\n",
       "                    created_date  publication_id  article_id    rating  funny  \\\n",
       "0  2015-09-29 10:50:41.987077+00               2        2006  rejected      0   \n",
       "1  2015-09-29 10:50:42.870083+00               2        2006  rejected      0   \n",
       "\n",
       "   wow  sad  likes  disagree  sexual_explicit  identity_annotator_count  \\\n",
       "0    0    0      0         0              0.0                         0   \n",
       "1    0    0      0         0              0.0                         0   \n",
       "\n",
       "   toxicity_annotator_count  \n",
       "0                         4  \n",
       "1                         4  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/luigibungaro/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = word_tokenize(df['comment_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "x = tokenizer.tokenize(df['comment_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/luigibungaro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sent=[]\n",
    "for w in x:\n",
    "    if w not in stop_words:\n",
    "        filtered_sent.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(417194, 301)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>300</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15586</th>\n",
       "      <td>anguilla</td>\n",
       "      <td>-0.1375</td>\n",
       "      <td>-0.0025</td>\n",
       "      <td>0.0629</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>-0.0375</td>\n",
       "      <td>0.0451</td>\n",
       "      <td>0.0994</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>-0.0238</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0029</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>-0.0511</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.0552</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>-0.0649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132071</th>\n",
       "      <td>felinity</td>\n",
       "      <td>-0.0217</td>\n",
       "      <td>-0.0653</td>\n",
       "      <td>0.0568</td>\n",
       "      <td>0.1026</td>\n",
       "      <td>0.1747</td>\n",
       "      <td>0.0759</td>\n",
       "      <td>-0.0519</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>-0.1229</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>0.0755</td>\n",
       "      <td>-0.0034</td>\n",
       "      <td>-0.0273</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>-0.0104</td>\n",
       "      <td>0.0788</td>\n",
       "      <td>-0.0143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0       1       2       3       4       5       6       7    \\\n",
       "15586   anguilla -0.1375 -0.0025  0.0629  0.0178 -0.0375  0.0451  0.0994   \n",
       "132071  felinity -0.0217 -0.0653  0.0568  0.1026  0.1747  0.0759 -0.0519   \n",
       "\n",
       "           8       9    ...     291     292     293     294     295     296  \\\n",
       "15586   0.1234 -0.0238  ... -0.0029  0.0484 -0.0511  0.0313  0.0055  0.0216   \n",
       "132071  0.0207 -0.1229  ... -0.0006  0.0326 -0.0024  0.0755 -0.0034 -0.0273   \n",
       "\n",
       "           297     298     299     300  \n",
       "15586   0.0552  0.0116  0.1056 -0.0649  \n",
       "132071  0.0556 -0.0104  0.0788 -0.0143  \n",
       "\n",
       "[2 rows x 301 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = pd.read_csv('numberbatch-en-17.06.txt',delimiter=' ',header=None)\n",
    "print(embedding.shape)\n",
    "embedding.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_string(string):\n",
    "    x = tokenizer.tokenize(string)\n",
    "    filtered_sent=[]\n",
    "    for w in x:\n",
    "        if w not in stop_words:\n",
    "            filtered_sent.append(w)\n",
    "    return filtered_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgh = preprocessing_string(\"This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1804874"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text value\n",
    "x = df['comment_text'][0]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target value\n",
    "df[df['comment_text']==x]['target'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 300)\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "labels = []\n",
    "j=0\n",
    "for i in df['comment_text'][:20000]:\n",
    "    j+=1\n",
    "    print(j, end='\\r')\n",
    "    preprocessed_string = preprocessing_string(i)\n",
    "    # print(preprocessed_string)\n",
    "    if embedding[0].isin(list(preprocessed_string)).sum()==0:\n",
    "        data.append(np.array([0.1]*300))\n",
    "    else:\n",
    "        embedded_vector = embedding[embedding[0].isin(preprocessed_string)][embedding.columns[1:]].mean().values\n",
    "        # print(type(embedded_vector))\n",
    "        data.append(embedded_vector)\n",
    "data = np.array(data)\n",
    "print(data.shape)\n",
    "labels = df.target\n",
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.DataFrame(data,columns=None)\n",
    "df_final['target']=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_pickle('df_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_pickle('df_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1804874, 20)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.159480</td>\n",
       "      <td>0.136200</td>\n",
       "      <td>0.025170</td>\n",
       "      <td>-0.009980</td>\n",
       "      <td>0.021080</td>\n",
       "      <td>-0.01213</td>\n",
       "      <td>0.121980</td>\n",
       "      <td>-0.069570</td>\n",
       "      <td>-0.049690</td>\n",
       "      <td>0.092570</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027710</td>\n",
       "      <td>-0.002890</td>\n",
       "      <td>0.007430</td>\n",
       "      <td>0.038270</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>-0.005830</td>\n",
       "      <td>-0.010490</td>\n",
       "      <td>-0.011680</td>\n",
       "      <td>-0.023620</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.186845</td>\n",
       "      <td>0.125036</td>\n",
       "      <td>0.017573</td>\n",
       "      <td>-0.036018</td>\n",
       "      <td>0.021982</td>\n",
       "      <td>-0.09090</td>\n",
       "      <td>0.096555</td>\n",
       "      <td>0.006936</td>\n",
       "      <td>-0.074545</td>\n",
       "      <td>0.067818</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021809</td>\n",
       "      <td>-0.013818</td>\n",
       "      <td>-0.020982</td>\n",
       "      <td>0.009927</td>\n",
       "      <td>0.013982</td>\n",
       "      <td>-0.019973</td>\n",
       "      <td>0.006991</td>\n",
       "      <td>0.022091</td>\n",
       "      <td>0.007345</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4        5         6  \\\n",
       "0  0.159480  0.136200  0.025170 -0.009980  0.021080 -0.01213  0.121980   \n",
       "1  0.186845  0.125036  0.017573 -0.036018  0.021982 -0.09090  0.096555   \n",
       "\n",
       "          7         8         9  ...       291       292       293       294  \\\n",
       "0 -0.069570 -0.049690  0.092570  ... -0.027710 -0.002890  0.007430  0.038270   \n",
       "1  0.006936 -0.074545  0.067818  ... -0.021809 -0.013818 -0.020982  0.009927   \n",
       "\n",
       "        295       296       297       298       299  target  \n",
       "0  0.034800 -0.005830 -0.010490 -0.011680 -0.023620     0.0  \n",
       "1  0.013982 -0.019973  0.006991  0.022091  0.007345     0.0  \n",
       "\n",
       "[2 rows x 301 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_final[df_final.columns[:-1]], df_final['target'],\n",
    "                                                    test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luigibungaro/myenv/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=300, units=400, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "/Users/luigibungaro/myenv/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=200, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/Users/luigibungaro/myenv/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=100, kernel_initializer=\"uniform\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/luigibungaro/myenv/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/Users/luigibungaro/myenv/lib/python3.7/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "16000/16000 [==============================] - 2s 104us/step - loss: 0.1398 - mean_absolute_error: 0.3330\n",
      "Epoch 2/200\n",
      "16000/16000 [==============================] - 1s 66us/step - loss: 0.0318 - mean_absolute_error: 0.1231: 0s - loss: 0.0318 - mean_absolute_error: 0.123\n",
      "Epoch 3/200\n",
      "16000/16000 [==============================] - 1s 67us/step - loss: 0.0296 - mean_absolute_error: 0.1212\n",
      "Epoch 4/200\n",
      "16000/16000 [==============================] - 1s 66us/step - loss: 0.0272 - mean_absolute_error: 0.1166\n",
      "Epoch 5/200\n",
      "16000/16000 [==============================] - 1s 67us/step - loss: 0.0249 - mean_absolute_error: 0.1104\n",
      "Epoch 6/200\n",
      "16000/16000 [==============================] - 1s 67us/step - loss: 0.0229 - mean_absolute_error: 0.1036\n",
      "Epoch 7/200\n",
      "16000/16000 [==============================] - 1s 71us/step - loss: 0.0213 - mean_absolute_error: 0.0971\n",
      "Epoch 8/200\n",
      "16000/16000 [==============================] - 1s 81us/step - loss: 0.0201 - mean_absolute_error: 0.0920\n",
      "Epoch 9/200\n",
      "16000/16000 [==============================] - 1s 73us/step - loss: 0.0191 - mean_absolute_error: 0.0881\n",
      "Epoch 10/200\n",
      "16000/16000 [==============================] - 1s 70us/step - loss: 0.0183 - mean_absolute_error: 0.0847\n",
      "Epoch 11/200\n",
      "16000/16000 [==============================] - 1s 69us/step - loss: 0.0177 - mean_absolute_error: 0.0823\n",
      "Epoch 12/200\n",
      "16000/16000 [==============================] - 1s 71us/step - loss: 0.0171 - mean_absolute_error: 0.0804\n",
      "Epoch 13/200\n",
      "16000/16000 [==============================] - 1s 72us/step - loss: 0.0164 - mean_absolute_error: 0.0784\n",
      "Epoch 14/200\n",
      "16000/16000 [==============================] - 1s 69us/step - loss: 0.0160 - mean_absolute_error: 0.0764\n",
      "Epoch 15/200\n",
      "16000/16000 [==============================] - 1s 71us/step - loss: 0.0156 - mean_absolute_error: 0.0752\n",
      "Epoch 16/200\n",
      "16000/16000 [==============================] - 1s 71us/step - loss: 0.0151 - mean_absolute_error: 0.0740\n",
      "Epoch 17/200\n",
      "16000/16000 [==============================] - 1s 88us/step - loss: 0.0147 - mean_absolute_error: 0.0729\n",
      "Epoch 18/200\n",
      "16000/16000 [==============================] - 1s 73us/step - loss: 0.0143 - mean_absolute_error: 0.0715\n",
      "Epoch 19/200\n",
      "16000/16000 [==============================] - 1s 71us/step - loss: 0.0140 - mean_absolute_error: 0.0705\n",
      "Epoch 20/200\n",
      "16000/16000 [==============================] - 1s 72us/step - loss: 0.0136 - mean_absolute_error: 0.0697\n",
      "Epoch 21/200\n",
      "16000/16000 [==============================] - 1s 72us/step - loss: 0.0133 - mean_absolute_error: 0.0684\n",
      "Epoch 22/200\n",
      "16000/16000 [==============================] - 1s 71us/step - loss: 0.0129 - mean_absolute_error: 0.0677\n",
      "Epoch 23/200\n",
      "16000/16000 [==============================] - 1s 72us/step - loss: 0.0126 - mean_absolute_error: 0.0664\n",
      "Epoch 24/200\n",
      "16000/16000 [==============================] - 1s 74us/step - loss: 0.0122 - mean_absolute_error: 0.0652\n",
      "Epoch 25/200\n",
      "16000/16000 [==============================] - 1s 72us/step - loss: 0.0119 - mean_absolute_error: 0.0645\n",
      "Epoch 26/200\n",
      "16000/16000 [==============================] - 1s 86us/step - loss: 0.0115 - mean_absolute_error: 0.0631\n",
      "Epoch 27/200\n",
      "16000/16000 [==============================] - 1s 74us/step - loss: 0.0112 - mean_absolute_error: 0.0622\n",
      "Epoch 28/200\n",
      "16000/16000 [==============================] - 1s 70us/step - loss: 0.0108 - mean_absolute_error: 0.0604\n",
      "Epoch 29/200\n",
      "16000/16000 [==============================] - 1s 70us/step - loss: 0.0105 - mean_absolute_error: 0.0593\n",
      "Epoch 30/200\n",
      "16000/16000 [==============================] - 1s 72us/step - loss: 0.0101 - mean_absolute_error: 0.0576\n",
      "Epoch 31/200\n",
      "16000/16000 [==============================] - 1s 73us/step - loss: 0.0097 - mean_absolute_error: 0.0564\n",
      "Epoch 32/200\n",
      "16000/16000 [==============================] - 1s 75us/step - loss: 0.0093 - mean_absolute_error: 0.0553\n",
      "Epoch 33/200\n",
      "16000/16000 [==============================] - 1s 81us/step - loss: 0.0092 - mean_absolute_error: 0.0547\n",
      "Epoch 34/200\n",
      "16000/16000 [==============================] - 1s 72us/step - loss: 0.0088 - mean_absolute_error: 0.0527\n",
      "Epoch 35/200\n",
      "16000/16000 [==============================] - 1s 74us/step - loss: 0.0084 - mean_absolute_error: 0.0516\n",
      "Epoch 36/200\n",
      "16000/16000 [==============================] - 1s 76us/step - loss: 0.0081 - mean_absolute_error: 0.0501\n",
      "Epoch 37/200\n",
      "16000/16000 [==============================] - 1s 75us/step - loss: 0.0080 - mean_absolute_error: 0.0498\n",
      "Epoch 38/200\n",
      "16000/16000 [==============================] - 1s 76us/step - loss: 0.0077 - mean_absolute_error: 0.0484\n",
      "Epoch 39/200\n",
      "16000/16000 [==============================] - 1s 76us/step - loss: 0.0074 - mean_absolute_error: 0.0474\n",
      "Epoch 40/200\n",
      "16000/16000 [==============================] - 1s 77us/step - loss: 0.0073 - mean_absolute_error: 0.0468\n",
      "Epoch 41/200\n",
      "16000/16000 [==============================] - 1s 77us/step - loss: 0.0071 - mean_absolute_error: 0.0462\n",
      "Epoch 42/200\n",
      "16000/16000 [==============================] - 1s 76us/step - loss: 0.0068 - mean_absolute_error: 0.0452\n",
      "Epoch 43/200\n",
      "16000/16000 [==============================] - 1s 92us/step - loss: 0.0065 - mean_absolute_error: 0.0446\n",
      "Epoch 44/200\n",
      "16000/16000 [==============================] - 1s 78us/step - loss: 0.0063 - mean_absolute_error: 0.0435\n",
      "Epoch 45/200\n",
      "16000/16000 [==============================] - 1s 77us/step - loss: 0.0061 - mean_absolute_error: 0.0425\n",
      "Epoch 46/200\n",
      "16000/16000 [==============================] - 1s 70us/step - loss: 0.0059 - mean_absolute_error: 0.0419\n",
      "Epoch 47/200\n",
      "16000/16000 [==============================] - 2s 98us/step - loss: 0.0058 - mean_absolute_error: 0.0415\n",
      "Epoch 48/200\n",
      "16000/16000 [==============================] - 1s 83us/step - loss: 0.0057 - mean_absolute_error: 0.0409\n",
      "Epoch 49/200\n",
      "16000/16000 [==============================] - 1s 81us/step - loss: 0.0055 - mean_absolute_error: 0.0405\n",
      "Epoch 50/200\n",
      "16000/16000 [==============================] - 1s 89us/step - loss: 0.0053 - mean_absolute_error: 0.0395\n",
      "Epoch 51/200\n",
      "16000/16000 [==============================] - 1s 87us/step - loss: 0.0052 - mean_absolute_error: 0.0389\n",
      "Epoch 52/200\n",
      "16000/16000 [==============================] - 1s 82us/step - loss: 0.0051 - mean_absolute_error: 0.0383\n",
      "Epoch 53/200\n",
      "16000/16000 [==============================] - 1s 82us/step - loss: 0.0050 - mean_absolute_error: 0.0380\n",
      "Epoch 54/200\n",
      "16000/16000 [==============================] - 1s 81us/step - loss: 0.0049 - mean_absolute_error: 0.0373\n",
      "Epoch 55/200\n",
      "16000/16000 [==============================] - 1s 82us/step - loss: 0.0048 - mean_absolute_error: 0.0367\n",
      "Epoch 56/200\n",
      "16000/16000 [==============================] - ETA: 0s - loss: 0.0048 - mean_absolute_error: 0.036 - 1s 84us/step - loss: 0.0048 - mean_absolute_error: 0.0365\n",
      "Epoch 57/200\n",
      "16000/16000 [==============================] - 1s 91us/step - loss: 0.0047 - mean_absolute_error: 0.0361\n",
      "Epoch 58/200\n",
      "16000/16000 [==============================] - 1s 81us/step - loss: 0.0045 - mean_absolute_error: 0.0352\n",
      "Epoch 59/200\n",
      "16000/16000 [==============================] - 1s 81us/step - loss: 0.0045 - mean_absolute_error: 0.0352\n",
      "Epoch 60/200\n",
      "16000/16000 [==============================] - 1s 80us/step - loss: 0.0045 - mean_absolute_error: 0.0350\n",
      "Epoch 61/200\n",
      "16000/16000 [==============================] - 1s 83us/step - loss: 0.0044 - mean_absolute_error: 0.0344\n",
      "Epoch 62/200\n",
      "16000/16000 [==============================] - 1s 67us/step - loss: 0.0043 - mean_absolute_error: 0.0340\n",
      "Epoch 63/200\n",
      "16000/16000 [==============================] - 1s 83us/step - loss: 0.0042 - mean_absolute_error: 0.0338\n",
      "Epoch 64/200\n",
      "16000/16000 [==============================] - 1s 88us/step - loss: 0.0041 - mean_absolute_error: 0.0331\n",
      "Epoch 65/200\n",
      "16000/16000 [==============================] - 1s 90us/step - loss: 0.0041 - mean_absolute_error: 0.0330\n",
      "Epoch 66/200\n",
      "16000/16000 [==============================] - 1s 83us/step - loss: 0.0040 - mean_absolute_error: 0.0325\n",
      "Epoch 67/200\n",
      "16000/16000 [==============================] - 1s 85us/step - loss: 0.0040 - mean_absolute_error: 0.0326\n",
      "Epoch 68/200\n",
      "16000/16000 [==============================] - 1s 85us/step - loss: 0.0039 - mean_absolute_error: 0.0319\n",
      "Epoch 69/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 1s 86us/step - loss: 0.0039 - mean_absolute_error: 0.0320\n",
      "Epoch 70/200\n",
      "16000/16000 [==============================] - 1s 69us/step - loss: 0.0039 - mean_absolute_error: 0.0315\n",
      "Epoch 71/200\n",
      "16000/16000 [==============================] - 1s 71us/step - loss: 0.0038 - mean_absolute_error: 0.0312\n",
      "Epoch 72/200\n",
      "16000/16000 [==============================] - 1s 71us/step - loss: 0.0037 - mean_absolute_error: 0.0308\n",
      "Epoch 73/200\n",
      "16000/16000 [==============================] - 1s 82us/step - loss: 0.0037 - mean_absolute_error: 0.0307\n",
      "Epoch 74/200\n",
      "16000/16000 [==============================] - 1s 71us/step - loss: 0.0036 - mean_absolute_error: 0.0301\n",
      "Epoch 75/200\n",
      "16000/16000 [==============================] - 1s 78us/step - loss: 0.0037 - mean_absolute_error: 0.0308\n",
      "Epoch 76/200\n",
      "16000/16000 [==============================] - 1s 83us/step - loss: 0.0036 - mean_absolute_error: 0.0297\n",
      "Epoch 77/200\n",
      "16000/16000 [==============================] - 1s 88us/step - loss: 0.0035 - mean_absolute_error: 0.0295\n",
      "Epoch 78/200\n",
      "16000/16000 [==============================] - 1s 82us/step - loss: 0.0035 - mean_absolute_error: 0.0291\n",
      "Epoch 79/200\n",
      "16000/16000 [==============================] - 1s 82us/step - loss: 0.0035 - mean_absolute_error: 0.0289\n",
      "Epoch 80/200\n",
      "16000/16000 [==============================] - 1s 78us/step - loss: 0.0034 - mean_absolute_error: 0.0285\n",
      "Epoch 81/200\n",
      "16000/16000 [==============================] - 1s 73us/step - loss: 0.0034 - mean_absolute_error: 0.0283\n",
      "Epoch 82/200\n",
      "16000/16000 [==============================] - 1s 74us/step - loss: 0.0034 - mean_absolute_error: 0.0284\n",
      "Epoch 83/200\n",
      "16000/16000 [==============================] - 1s 74us/step - loss: 0.0034 - mean_absolute_error: 0.0284\n",
      "Epoch 84/200\n",
      "16000/16000 [==============================] - 1s 86us/step - loss: 0.0033 - mean_absolute_error: 0.0278\n",
      "Epoch 85/200\n",
      "16000/16000 [==============================] - 1s 76us/step - loss: 0.0034 - mean_absolute_error: 0.0282\n",
      "Epoch 86/200\n",
      "16000/16000 [==============================] - 1s 74us/step - loss: 0.0033 - mean_absolute_error: 0.0277\n",
      "Epoch 87/200\n",
      "16000/16000 [==============================] - 1s 75us/step - loss: 0.0033 - mean_absolute_error: 0.0274\n",
      "Epoch 88/200\n",
      "16000/16000 [==============================] - 1s 74us/step - loss: 0.0033 - mean_absolute_error: 0.0275\n",
      "Epoch 89/200\n",
      "16000/16000 [==============================] - 1s 74us/step - loss: 0.0033 - mean_absolute_error: 0.0276\n",
      "Epoch 90/200\n",
      "16000/16000 [==============================] - 1s 76us/step - loss: 0.0032 - mean_absolute_error: 0.0267\n",
      "Epoch 91/200\n",
      "16000/16000 [==============================] - 1s 76us/step - loss: 0.0031 - mean_absolute_error: 0.0266\n",
      "Epoch 92/200\n",
      "16000/16000 [==============================] - 1s 76us/step - loss: 0.0031 - mean_absolute_error: 0.0262\n",
      "Epoch 93/200\n",
      "16000/16000 [==============================] - 1s 77us/step - loss: 0.0031 - mean_absolute_error: 0.0263\n",
      "Epoch 94/200\n",
      "16000/16000 [==============================] - 1s 84us/step - loss: 0.0031 - mean_absolute_error: 0.0263\n",
      "Epoch 95/200\n",
      "16000/16000 [==============================] - 1s 84us/step - loss: 0.0031 - mean_absolute_error: 0.0260\n",
      "Epoch 96/200\n",
      "16000/16000 [==============================] - 1s 80us/step - loss: 0.0030 - mean_absolute_error: 0.0257\n",
      "Epoch 97/200\n",
      "16000/16000 [==============================] - 1s 79us/step - loss: 0.0030 - mean_absolute_error: 0.0253\n",
      "Epoch 98/200\n",
      "16000/16000 [==============================] - 1s 83us/step - loss: 0.0030 - mean_absolute_error: 0.0255\n",
      "Epoch 99/200\n",
      "16000/16000 [==============================] - 1s 76us/step - loss: 0.0029 - mean_absolute_error: 0.0249\n",
      "Epoch 100/200\n",
      "16000/16000 [==============================] - 1s 89us/step - loss: 0.0029 - mean_absolute_error: 0.0243\n",
      "Epoch 101/200\n",
      "16000/16000 [==============================] - 1s 81us/step - loss: 0.0029 - mean_absolute_error: 0.0248\n",
      "Epoch 102/200\n",
      "16000/16000 [==============================] - 1s 93us/step - loss: 0.0032 - mean_absolute_error: 0.0269\n",
      "Epoch 103/200\n",
      "16000/16000 [==============================] - 1s 86us/step - loss: 0.0030 - mean_absolute_error: 0.0253\n",
      "Epoch 104/200\n",
      "16000/16000 [==============================] - 1s 84us/step - loss: 0.0028 - mean_absolute_error: 0.0244\n",
      "Epoch 105/200\n",
      "16000/16000 [==============================] - 1s 87us/step - loss: 0.0028 - mean_absolute_error: 0.0241\n",
      "Epoch 106/200\n",
      "16000/16000 [==============================] - 1s 85us/step - loss: 0.0027 - mean_absolute_error: 0.0236\n",
      "Epoch 107/200\n",
      "16000/16000 [==============================] - 1s 85us/step - loss: 0.0027 - mean_absolute_error: 0.0232\n",
      "Epoch 108/200\n",
      "16000/16000 [==============================] - 1s 80us/step - loss: 0.0028 - mean_absolute_error: 0.0239\n",
      "Epoch 109/200\n",
      "16000/16000 [==============================] - 1s 79us/step - loss: 0.0029 - mean_absolute_error: 0.0248\n",
      "Epoch 110/200\n",
      "16000/16000 [==============================] - 1s 78us/step - loss: 0.0027 - mean_absolute_error: 0.0238\n",
      "Epoch 111/200\n",
      "16000/16000 [==============================] - 1s 78us/step - loss: 0.0027 - mean_absolute_error: 0.0234\n",
      "Epoch 112/200\n",
      "16000/16000 [==============================] - 1s 78us/step - loss: 0.0027 - mean_absolute_error: 0.0233\n",
      "Epoch 113/200\n",
      "16000/16000 [==============================] - 1s 87us/step - loss: 0.0026 - mean_absolute_error: 0.0226\n",
      "Epoch 114/200\n",
      "16000/16000 [==============================] - 1s 80us/step - loss: 0.0027 - mean_absolute_error: 0.0231\n",
      "Epoch 115/200\n",
      "16000/16000 [==============================] - 1s 87us/step - loss: 0.0026 - mean_absolute_error: 0.0226\n",
      "Epoch 116/200\n",
      "16000/16000 [==============================] - 1s 83us/step - loss: 0.0026 - mean_absolute_error: 0.0223\n",
      "Epoch 117/200\n",
      "16000/16000 [==============================] - 1s 83us/step - loss: 0.0025 - mean_absolute_error: 0.0218\n",
      "Epoch 118/200\n",
      "16000/16000 [==============================] - 1s 79us/step - loss: 0.0025 - mean_absolute_error: 0.0223\n",
      "Epoch 119/200\n",
      "16000/16000 [==============================] - 1s 86us/step - loss: 0.0025 - mean_absolute_error: 0.0224\n",
      "Epoch 120/200\n",
      "16000/16000 [==============================] - 2s 95us/step - loss: 0.0025 - mean_absolute_error: 0.0224\n",
      "Epoch 121/200\n",
      "16000/16000 [==============================] - 1s 88us/step - loss: 0.0025 - mean_absolute_error: 0.0218: 1s - loss: 0.0021 - mea\n",
      "Epoch 122/200\n",
      "16000/16000 [==============================] - 1s 82us/step - loss: 0.0025 - mean_absolute_error: 0.0218\n",
      "Epoch 123/200\n",
      "16000/16000 [==============================] - 1s 87us/step - loss: 0.0024 - mean_absolute_error: 0.0210\n",
      "Epoch 124/200\n",
      "16000/16000 [==============================] - 1s 82us/step - loss: 0.0024 - mean_absolute_error: 0.0211\n",
      "Epoch 125/200\n",
      "16000/16000 [==============================] - 1s 82us/step - loss: 0.0024 - mean_absolute_error: 0.0212\n",
      "Epoch 126/200\n",
      "16000/16000 [==============================] - 1s 80us/step - loss: 0.0025 - mean_absolute_error: 0.0222\n",
      "Epoch 127/200\n",
      "16000/16000 [==============================] - 1s 81us/step - loss: 0.0024 - mean_absolute_error: 0.0210\n",
      "Epoch 128/200\n",
      "16000/16000 [==============================] - 1s 82us/step - loss: 0.0023 - mean_absolute_error: 0.0204\n",
      "Epoch 129/200\n",
      "16000/16000 [==============================] - 1s 81us/step - loss: 0.0023 - mean_absolute_error: 0.0201\n",
      "Epoch 130/200\n",
      "16000/16000 [==============================] - 1s 82us/step - loss: 0.0023 - mean_absolute_error: 0.0202\n",
      "Epoch 131/200\n",
      "16000/16000 [==============================] - 1s 84us/step - loss: 0.0023 - mean_absolute_error: 0.0200\n",
      "Epoch 132/200\n",
      "16000/16000 [==============================] - 1s 82us/step - loss: 0.0022 - mean_absolute_error: 0.0194\n",
      "Epoch 133/200\n",
      "16000/16000 [==============================] - 1s 82us/step - loss: 0.0023 - mean_absolute_error: 0.0200\n",
      "Epoch 134/200\n",
      "16000/16000 [==============================] - 1s 85us/step - loss: 0.0022 - mean_absolute_error: 0.0200\n",
      "Epoch 135/200\n",
      "16000/16000 [==============================] - 1s 84us/step - loss: 0.0022 - mean_absolute_error: 0.0199\n",
      "Epoch 136/200\n",
      "16000/16000 [==============================] - 1s 83us/step - loss: 0.0022 - mean_absolute_error: 0.0197\n",
      "Epoch 137/200\n",
      "16000/16000 [==============================] - 1s 83us/step - loss: 0.0021 - mean_absolute_error: 0.0192\n",
      "Epoch 138/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 1s 71us/step - loss: 0.0021 - mean_absolute_error: 0.0191\n",
      "Epoch 139/200\n",
      "16000/16000 [==============================] - 1s 69us/step - loss: 0.0022 - mean_absolute_error: 0.0195\n",
      "Epoch 140/200\n",
      "16000/16000 [==============================] - 1s 70us/step - loss: 0.0021 - mean_absolute_error: 0.0189\n",
      "Epoch 141/200\n",
      "16000/16000 [==============================] - 1s 89us/step - loss: 0.0020 - mean_absolute_error: 0.0182\n",
      "Epoch 142/200\n",
      "16000/16000 [==============================] - 1s 88us/step - loss: 0.0021 - mean_absolute_error: 0.0193\n",
      "Epoch 143/200\n",
      "16000/16000 [==============================] - 1s 87us/step - loss: 0.0020 - mean_absolute_error: 0.0181\n",
      "Epoch 144/200\n",
      "16000/16000 [==============================] - 2s 98us/step - loss: 0.0020 - mean_absolute_error: 0.0180\n",
      "Epoch 145/200\n",
      "16000/16000 [==============================] - 1s 72us/step - loss: 0.0020 - mean_absolute_error: 0.0182\n",
      "Epoch 146/200\n",
      "16000/16000 [==============================] - 1s 72us/step - loss: 0.0020 - mean_absolute_error: 0.0180\n",
      "Epoch 147/200\n",
      "16000/16000 [==============================] - 1s 71us/step - loss: 0.0020 - mean_absolute_error: 0.0179\n",
      "Epoch 148/200\n",
      "16000/16000 [==============================] - 1s 82us/step - loss: 0.0020 - mean_absolute_error: 0.0172\n",
      "Epoch 149/200\n",
      "16000/16000 [==============================] - 1s 83us/step - loss: 0.0020 - mean_absolute_error: 0.0183\n",
      "Epoch 150/200\n",
      "16000/16000 [==============================] - 1s 76us/step - loss: 0.0020 - mean_absolute_error: 0.0178\n",
      "Epoch 151/200\n",
      "16000/16000 [==============================] - 1s 74us/step - loss: 0.0019 - mean_absolute_error: 0.0171\n",
      "Epoch 152/200\n",
      "16000/16000 [==============================] - 1s 73us/step - loss: 0.0019 - mean_absolute_error: 0.0164\n",
      "Epoch 153/200\n",
      "16000/16000 [==============================] - 1s 88us/step - loss: 0.0019 - mean_absolute_error: 0.0171\n",
      "Epoch 154/200\n",
      "16000/16000 [==============================] - 1s 82us/step - loss: 0.0020 - mean_absolute_error: 0.0174\n",
      "Epoch 155/200\n",
      "16000/16000 [==============================] - 2s 95us/step - loss: 0.0019 - mean_absolute_error: 0.0165\n",
      "Epoch 156/200\n",
      "16000/16000 [==============================] - 1s 78us/step - loss: 0.0019 - mean_absolute_error: 0.0165\n",
      "Epoch 157/200\n",
      "16000/16000 [==============================] - 1s 87us/step - loss: 0.0018 - mean_absolute_error: 0.0160\n",
      "Epoch 158/200\n",
      "16000/16000 [==============================] - 1s 79us/step - loss: 0.0019 - mean_absolute_error: 0.0173\n",
      "Epoch 159/200\n",
      "16000/16000 [==============================] - 1s 85us/step - loss: 0.0019 - mean_absolute_error: 0.0166\n",
      "Epoch 160/200\n",
      "16000/16000 [==============================] - 1s 92us/step - loss: 0.0018 - mean_absolute_error: 0.0164\n",
      "Epoch 161/200\n",
      "16000/16000 [==============================] - 1s 84us/step - loss: 0.0019 - mean_absolute_error: 0.0165\n",
      "Epoch 162/200\n",
      "16000/16000 [==============================] - 1s 91us/step - loss: 0.0018 - mean_absolute_error: 0.0159\n",
      "Epoch 163/200\n",
      "16000/16000 [==============================] - 1s 75us/step - loss: 0.0018 - mean_absolute_error: 0.0159\n",
      "Epoch 164/200\n",
      "16000/16000 [==============================] - 1s 84us/step - loss: 0.0018 - mean_absolute_error: 0.0160\n",
      "Epoch 165/200\n",
      "16000/16000 [==============================] - 1s 66us/step - loss: 0.0019 - mean_absolute_error: 0.0161\n",
      "Epoch 166/200\n",
      "16000/16000 [==============================] - 1s 65us/step - loss: 0.0019 - mean_absolute_error: 0.0162\n",
      "Epoch 167/200\n",
      "16000/16000 [==============================] - 1s 88us/step - loss: 0.0018 - mean_absolute_error: 0.0159\n",
      "Epoch 168/200\n",
      "16000/16000 [==============================] - 2s 97us/step - loss: 0.0018 - mean_absolute_error: 0.0152\n",
      "Epoch 169/200\n",
      "16000/16000 [==============================] - 1s 86us/step - loss: 0.0018 - mean_absolute_error: 0.0152\n",
      "Epoch 170/200\n",
      "16000/16000 [==============================] - 1s 92us/step - loss: 0.0018 - mean_absolute_error: 0.0153\n",
      "Epoch 171/200\n",
      "16000/16000 [==============================] - 1s 78us/step - loss: 0.0018 - mean_absolute_error: 0.0160\n",
      "Epoch 172/200\n",
      "16000/16000 [==============================] - 1s 84us/step - loss: 0.0017 - mean_absolute_error: 0.0149\n",
      "Epoch 173/200\n",
      "16000/16000 [==============================] - 1s 84us/step - loss: 0.0017 - mean_absolute_error: 0.0151\n",
      "Epoch 174/200\n",
      "16000/16000 [==============================] - 1s 77us/step - loss: 0.0017 - mean_absolute_error: 0.0149\n",
      "Epoch 175/200\n",
      "16000/16000 [==============================] - 1s 85us/step - loss: 0.0018 - mean_absolute_error: 0.0154\n",
      "Epoch 176/200\n",
      "16000/16000 [==============================] - 2s 119us/step - loss: 0.0017 - mean_absolute_error: 0.0144 1s - loss: 0.00\n",
      "Epoch 177/200\n",
      "16000/16000 [==============================] - 2s 106us/step - loss: 0.0017 - mean_absolute_error: 0.0144\n",
      "Epoch 178/200\n",
      "16000/16000 [==============================] - 1s 86us/step - loss: 0.0017 - mean_absolute_error: 0.0152\n",
      "Epoch 179/200\n",
      "16000/16000 [==============================] - 1s 81us/step - loss: 0.0017 - mean_absolute_error: 0.0147\n",
      "Epoch 180/200\n",
      "16000/16000 [==============================] - 1s 79us/step - loss: 0.0017 - mean_absolute_error: 0.0142\n",
      "Epoch 181/200\n",
      "16000/16000 [==============================] - 1s 77us/step - loss: 0.0017 - mean_absolute_error: 0.0144\n",
      "Epoch 182/200\n",
      "16000/16000 [==============================] - 1s 80us/step - loss: 0.0017 - mean_absolute_error: 0.0154\n",
      "Epoch 183/200\n",
      "16000/16000 [==============================] - 1s 80us/step - loss: 0.0016 - mean_absolute_error: 0.0139\n",
      "Epoch 184/200\n",
      "16000/16000 [==============================] - 1s 81us/step - loss: 0.0016 - mean_absolute_error: 0.0137\n",
      "Epoch 185/200\n",
      "16000/16000 [==============================] - 1s 87us/step - loss: 0.0016 - mean_absolute_error: 0.0136\n",
      "Epoch 186/200\n",
      "16000/16000 [==============================] - 1s 88us/step - loss: 0.0016 - mean_absolute_error: 0.0139\n",
      "Epoch 187/200\n",
      "16000/16000 [==============================] - 1s 81us/step - loss: 0.0017 - mean_absolute_error: 0.0148\n",
      "Epoch 188/200\n",
      "16000/16000 [==============================] - 1s 81us/step - loss: 0.0017 - mean_absolute_error: 0.0141\n",
      "Epoch 189/200\n",
      "16000/16000 [==============================] - 1s 80us/step - loss: 0.0016 - mean_absolute_error: 0.0134\n",
      "Epoch 190/200\n",
      "16000/16000 [==============================] - 1s 81us/step - loss: 0.0016 - mean_absolute_error: 0.0132\n",
      "Epoch 191/200\n",
      "16000/16000 [==============================] - 1s 81us/step - loss: 0.0016 - mean_absolute_error: 0.0134\n",
      "Epoch 192/200\n",
      "16000/16000 [==============================] - 1s 83us/step - loss: 0.0016 - mean_absolute_error: 0.0130\n",
      "Epoch 193/200\n",
      "16000/16000 [==============================] - 1s 82us/step - loss: 0.0016 - mean_absolute_error: 0.0133\n",
      "Epoch 194/200\n",
      "16000/16000 [==============================] - 2s 96us/step - loss: 0.0016 - mean_absolute_error: 0.0139\n",
      "Epoch 195/200\n",
      "16000/16000 [==============================] - 1s 84us/step - loss: 0.0016 - mean_absolute_error: 0.0132\n",
      "Epoch 196/200\n",
      "16000/16000 [==============================] - 1s 94us/step - loss: 0.0015 - mean_absolute_error: 0.0127\n",
      "Epoch 197/200\n",
      "16000/16000 [==============================] - 1s 81us/step - loss: 0.0015 - mean_absolute_error: 0.0126\n",
      "Epoch 198/200\n",
      "16000/16000 [==============================] - 1s 86us/step - loss: 0.0016 - mean_absolute_error: 0.0136\n",
      "Epoch 199/200\n",
      "16000/16000 [==============================] - 1s 82us/step - loss: 0.0016 - mean_absolute_error: 0.0139\n",
      "Epoch 200/200\n",
      "16000/16000 [==============================] - 1s 85us/step - loss: 0.0016 - mean_absolute_error: 0.0135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12c054c88>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 400, init = 'uniform', activation = 'relu', input_dim = 300))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 200, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 100, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 50, init = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.00011)\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = adam, loss = 'mean_squared_error', metrics = ['mae'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 100, epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('k_toxicity/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97320, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000000</td>\n",
       "      <td>Jeff Sessions is another one of Trump's Orwell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7000001</td>\n",
       "      <td>I actually inspected the infrastructure on Gra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                       comment_text\n",
       "0  7000000  Jeff Sessions is another one of Trump's Orwell...\n",
       "1  7000001  I actually inspected the infrastructure on Gra..."
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test.shape)\n",
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97320, 300)\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "labels = []\n",
    "j=0\n",
    "for i in test['comment_text']:\n",
    "    j+=1\n",
    "    print(j, end='\\r')\n",
    "    preprocessed_string = preprocessing_string(i)\n",
    "    # print(preprocessed_string)\n",
    "    if embedding[0].isin(list(preprocessed_string)).sum()==0:\n",
    "        data.append(np.array([0.1]*300))\n",
    "    else:\n",
    "        embedded_vector = embedding[embedding[0].isin(preprocessed_string)][embedding.columns[1:]].mean().values\n",
    "        # print(type(embedded_vector))\n",
    "        data.append(embedded_vector)\n",
    "data = np.array(data)\n",
    "print(data.shape)\n",
    "labels = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97320, 300)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_final_df = pd.DataFrame(data,columns=None)\n",
    "test_final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final_df.to_pickle('df_final_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final_df = pd.read_pickle('df_final_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97320, 300)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.135491</td>\n",
       "      <td>0.096145</td>\n",
       "      <td>-0.013600</td>\n",
       "      <td>-0.095782</td>\n",
       "      <td>-0.018945</td>\n",
       "      <td>0.033373</td>\n",
       "      <td>0.074082</td>\n",
       "      <td>-0.002736</td>\n",
       "      <td>-0.035864</td>\n",
       "      <td>0.025673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028473</td>\n",
       "      <td>-0.003955</td>\n",
       "      <td>0.012527</td>\n",
       "      <td>0.017855</td>\n",
       "      <td>-0.007791</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>0.013336</td>\n",
       "      <td>0.004036</td>\n",
       "      <td>-0.0041</td>\n",
       "      <td>0.001373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.077924</td>\n",
       "      <td>0.053862</td>\n",
       "      <td>-0.011543</td>\n",
       "      <td>-0.057910</td>\n",
       "      <td>-0.086705</td>\n",
       "      <td>0.023605</td>\n",
       "      <td>0.095248</td>\n",
       "      <td>0.037181</td>\n",
       "      <td>-0.036629</td>\n",
       "      <td>-0.000733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>-0.018214</td>\n",
       "      <td>0.020190</td>\n",
       "      <td>0.004210</td>\n",
       "      <td>-0.018438</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>-0.005829</td>\n",
       "      <td>-0.0140</td>\n",
       "      <td>0.011967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.135491  0.096145 -0.013600 -0.095782 -0.018945  0.033373  0.074082   \n",
       "1  0.077924  0.053862 -0.011543 -0.057910 -0.086705  0.023605  0.095248   \n",
       "\n",
       "        7         8         9    ...       290       291       292       293  \\\n",
       "0 -0.002736 -0.035864  0.025673  ...  0.028473 -0.003955  0.012527  0.017855   \n",
       "1  0.037181 -0.036629 -0.000733  ...  0.004733 -0.018214  0.020190  0.004210   \n",
       "\n",
       "        294       295       296       297     298       299  \n",
       "0 -0.007791  0.002627  0.013336  0.004036 -0.0041  0.001373  \n",
       "1 -0.018438  0.003914  0.002695 -0.005829 -0.0140  0.011967  \n",
       "\n",
       "[2 rows x 300 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_final_df.shape)\n",
    "test_final_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = classifier.predict(test_final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00083357096, 0.0007523596, 0.18382111, 0.0219495, 0.28862673]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_pred)\n",
    "final_pred = [i[0] for i in final_pred]\n",
    "final_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97320, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7000001</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  prediction\n",
       "0  7000000         0.0\n",
       "1  7000001         0.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv('k_toxicity/sample_submission.csv')\n",
    "print(sample_submission.shape)\n",
    "sample_submission.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['prediction'] = final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('submission_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_",
   "language": "python",
   "name": "myenv_"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
